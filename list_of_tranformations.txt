Some common Transformations are presented on the follow link : https://www.cdata.com/sync/about/etl-transformation.rst

A consolidated list of Transformations by category is given below

•	Data Cleaning
   o	Handling Missing Values: Filling in missing data using default values, averages, or interpolation.
   o	Removing Duplicates: Identifying and removing duplicate rows or records.
   o	Standardizing Formats: Converting inconsistent into a unified format.
   o	Error Correction: Fixing typographical errors or invalid entries.

•	Data Integration
   o	Combining Data: Merging data from multiple sources (e.g., databases or files) into a single unified format.
   o	Deduplication: Ensuring that no redundant records exist after merging.

•	Data Aggregation
   o	Summarization: Creating summaries such as totals, averages, or counts.
   o	Grouping: Grouping data by specific fields and applying aggregate functions.

•	Data Filtering
   o	Row Filtering: Excluding rows that don't meet specific criteria (e.g., transactions over a certain threshold).
   o	Column Filtering: Dropping unnecessary or irrelevant columns.

•	Data Enrichment
   o	Adding Calculated Fields: Creating new columns based on calculations (e.g., profit = revenue - cost).
   o	Lookup and Reference: Adding information by referencing external datasets.

•	Data Standardization
   o	Renaming Columns: Renaming fields to meet naming conventions or improve clarity.
   o	Standardizing Units: Converting units to a consistent measure (e.g., converting all weights to kilograms).
   o	Capitalization Rules: Standardizing text formats (e.g., making all names uppercase).

•	Data Validation
   o	Range Checks: Ensuring numeric values fall within acceptable ranges.
   o	Domain Validation: Checking that values belong to a predefined set of acceptable options.

•	Data Transformation
   o	Type Conversion: Changing data types (e.g., string to integer).
   o	Pivoting and Unpivoting: Converting rows to columns or vice versa for analytical compatibility.
   o	Normalization: Scaling data to fit within a specific range (e.g., 0–1).
   o	Denormalization: Flattening data structures to simplify querying or analysis.

•	Data Sorting
   o	Sorting Rows: Arranging records in ascending or descending order based on one or more fields.

•	Key Handling
   o	Primary Key Generation: Creating unique identifiers for rows.
   o	Foreign Key Mapping: Establishing relationships between datasets.

•	Geospatial Transformations
   o	Address Parsing: Breaking down an address into components like street, city, and postal code.
   o	Geocoding: Adding latitude and longitude coordinates to location data.

•	Text Manipulation
   o	Splitting or Joining Strings: Dividing a string into components or concatenating multiple strings.
   o	Trimming: Removing leading or trailing spaces.
   o	Regex Operations: Using regular expressions to extract or manipulate text.

•	Time-Based Transformations
   o	Date Extraction: Extracting parts of dates (e.g., year, month).
   o	Time Series Alignment: Aggregating or interpolating time-series data for consistency.

•	Anonymization and Masking
   o	Data Masking: Replacing sensitive information with dummy data.
   o	Tokenization: Replacing sensitive data with unique identifiers.

•	Data Splitting
   o	Partitioning: Dividing data into segments for better management or analysis (e.g., splitting by region).

Each transformation addresses a specific need for making data actionable, clean, and efficient for downstream processes.
